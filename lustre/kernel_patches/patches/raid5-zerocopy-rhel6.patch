diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c
index 9cd137e..6d1a32d 100644
Index: linux-2.6.32-131.0.15.el6.x86_64/drivers/md/raid5.c
===================================================================
--- linux-2.6.32-131.0.15.el6.x86_64.orig/drivers/md/raid5.c	2011-05-19 20:57:16.000000000 +0300
+++ linux-2.6.32-131.0.15.el6.x86_64/drivers/md/raid5.c	2011-05-19 21:08:10.000000000 +0300
@@ -193,6 +193,25 @@ static int stripe_operations_active(stru
 	       test_bit(STRIPE_COMPUTE_RUN, &sh->state);
 }
 
+static struct page *zero_copy_data(struct bio *bio, sector_t sector)
+{
+	sector_t bi_sector = bio->bi_sector;
+	struct page *page = NULL;
+	struct bio_vec *bvl;
+	int i;
+
+	bio_for_each_segment(bvl, bio, i) {
+		if (sector == bi_sector && bvl->bv_len == STRIPE_SIZE) {
+			page = bvl->bv_page;
+			if (PageConstant(page))
+				return page;
+			return NULL;
+		}
+		bi_sector += bvl->bv_len >> 9;
+	}
+	return NULL;
+}
+
 static void __release_stripe(raid5_conf_t *conf, struct stripe_head *sh)
 {
 	if (atomic_dec_and_test(&sh->count)) {
@@ -563,6 +582,14 @@ static void ops_run_io(struct stripe_hea
 				set_bit(STRIPE_DEGRADED, &sh->state);
 			pr_debug("skip op %ld on disc %d for sector %llu\n",
 				bi->bi_rw, i, (unsigned long long)sh->sector);
+
+			if (test_bit(R5_Direct, &sh->dev[i].flags)) {
+				struct page *page = bio_iovec_idx(&sh->dev[i].req, 0)->bv_page;
+				BUG_ON(page == sh->dev[i].page);
+				bio_iovec_idx(&sh->dev[i].req, 0)->bv_page = sh->dev[i].page;
+				kunmap(page);
+			}
+
 			clear_bit(R5_LOCKED, &sh->dev[i].flags);
 			set_bit(STRIPE_HANDLE, &sh->state);
 		}
@@ -1009,6 +1036,36 @@ ops_run_prexor(struct stripe_head *sh, s
 	return tx;
 }
 
+static int try_reuse_data_page(struct r5dev *dev)
+{
+	struct bio *wbi = dev->written;
+	struct page *page;
+	sector_t sector = dev->sector;
+
+	BUG_ON(!test_bit(R5_LOCKED, &dev->flags));
+	BUG_ON(test_bit(R5_Direct, &dev->flags));
+
+	/* check if it's covered by a single page
+	   and the whole stripe is written at once.
+	 * in this case we can avoid memcpy() */
+	if (wbi && !wbi->bi_next && test_bit(R5_OVERWRITE, &dev->flags) &&
+	    test_bit(R5_Insync, &dev->flags)) {
+		page = zero_copy_data(wbi, sector);
+		if (page) {
+			/* The pointer must be restored whenever the LOCKED
+			 * gets cleared. */
+			kmap(page); /* for sync_xor on 32-bit systems */
+			bio_iovec_idx(&dev->req, 0)->bv_page = page;
+			set_bit(R5_Direct, &dev->flags);
+			clear_bit(R5_UPTODATE, &dev->flags);
+			clear_bit(R5_OVERWRITE, &dev->flags);
+			return 1;
+		}
+	}
+
+	return 0;
+}
+
 static struct dma_async_tx_descriptor *
 ops_run_biodrain(struct stripe_head *sh, struct dma_async_tx_descriptor *tx)
 {
@@ -1032,6 +1089,11 @@ ops_run_biodrain(struct stripe_head *sh,
 			wbi = dev->written = chosen;
 			spin_unlock(&sh->lock);
 
+			if (try_reuse_data_page(dev)) {
+				atomic_inc(&sh->raid_conf->writes_zcopy);
+				continue;
+			}
+
 			while (wbi && wbi->bi_sector <
 				dev->sector + STRIPE_SECTORS) {
 				if (wbi->bi_rw & REQ_FUA)
@@ -1644,6 +1706,7 @@ static void raid5_end_read_request(struc
 		}
 	}
 	rdev_dec_pending(conf->disks[i].rdev, conf->mddev);
+	BUG_ON(bio_iovec_idx(&sh->dev[i].req, 0)->bv_page != sh->dev[i].page);
 	clear_bit(R5_LOCKED, &sh->dev[i].flags);
 	set_bit(STRIPE_HANDLE, &sh->state);
 	release_stripe(sh);
@@ -1673,6 +1736,14 @@ static void raid5_end_write_request(stru
 
 	rdev_dec_pending(conf->disks[i].rdev, conf->mddev);
 	
+	if (test_bit(R5_Direct, &sh->dev[i].flags)) {
+		struct page *page = bio_iovec_idx(&sh->dev[i].req, 0)->bv_page;
+		BUG_ON(page == sh->dev[i].page);
+		bio_iovec_idx(&sh->dev[i].req, 0)->bv_page = sh->dev[i].page;
+		kunmap(page);
+	} else {
+		BUG_ON(bio_iovec_idx(&sh->dev[i].req, 0)->bv_page != sh->dev[i].page);
+	}
 	clear_bit(R5_LOCKED, &sh->dev[i].flags);
 	set_bit(STRIPE_HANDLE, &sh->state);
 	release_stripe(sh);
@@ -2515,7 +2586,8 @@ static void handle_stripe_clean_event(ra
 		if (sh->dev[i].written) {
 			dev = &sh->dev[i];
 			if (!test_bit(R5_LOCKED, &dev->flags) &&
-				test_bit(R5_UPTODATE, &dev->flags)) {
+				(test_bit(R5_UPTODATE, &dev->flags) ||
+				 test_bit(R5_Direct, &dev->flags))) {
 				/* We can return any write requests */
 				struct bio *wbi, *wbi2;
 				int bitmap_end = 0;
@@ -2523,6 +2595,7 @@ static void handle_stripe_clean_event(ra
 				spin_lock_irq(&conf->device_lock);
 				wbi = dev->written;
 				dev->written = NULL;
+				clear_bit(R5_Direct, &dev->flags);
 				while (wbi && wbi->bi_sector <
 					dev->sector + STRIPE_SECTORS) {
 					wbi2 = r5_next_bio(wbi, dev->sector);
@@ -3142,6 +3215,7 @@ static void handle_stripe5(struct stripe
 	 * is safe, or on a failed drive
 	 */
 	dev = &sh->dev[sh->pd_idx];
+
 	if ( s.written &&
 	     ((test_bit(R5_Insync, &dev->flags) &&
 	       !test_bit(R5_LOCKED, &dev->flags) &&
@@ -5209,6 +5283,7 @@ static int run(mddev_t *mddev)
 
 		mddev->queue->backing_dev_info.congested_data = mddev;
 		mddev->queue->backing_dev_info.congested_fn = raid5_congested;
+		mddev->queue->backing_dev_info.capabilities |= BDI_CAP_PAGE_CONSTANT_WRITE;
 		mddev->queue->unplug_fn = raid5_unplug_queue;
 
 		chunk_size = mddev->chunk_sectors << 9;
Index: linux-2.6.32-131.0.15.el6.x86_64/drivers/md/raid5.h
===================================================================
--- linux-2.6.32-131.0.15.el6.x86_64.orig/drivers/md/raid5.h	2011-05-10 21:38:34.000000000 +0300
+++ linux-2.6.32-131.0.15.el6.x86_64/drivers/md/raid5.h	2011-05-19 21:08:39.000000000 +0300
@@ -276,6 +276,8 @@ struct r6_state {
 				    */
 #define R5_Wantdrain	13 /* dev->towrite needs to be drained */
 #define R5_WantFUA	14	/* Write should be FUA */
+#define	R5_Direct	31	/* Use the pages in bio to do the write directly. */
+
 /*
  * Write method
  */
Index: linux-2.6.32-131.0.15.el6.x86_64/include/linux/backing-dev.h
===================================================================
--- linux-2.6.32-131.0.15.el6.x86_64.orig/include/linux/backing-dev.h	2011-05-10 21:37:43.000000000 +0300
+++ linux-2.6.32-131.0.15.el6.x86_64/include/linux/backing-dev.h	2011-05-19 21:06:31.000000000 +0300
@@ -230,6 +230,7 @@ int bdi_set_max_ratio(struct backing_dev
 #define BDI_CAP_EXEC_MAP	0x00000040
 #define BDI_CAP_NO_ACCT_WB	0x00000080
 #define BDI_CAP_SWAP_BACKED	0x00000100
+#define BDI_CAP_PAGE_CONSTANT_WRITE	0x00000200	/* Zcopy write - for raid5 */
 
 #define BDI_CAP_VMFLAGS \
 	(BDI_CAP_READ_MAP | BDI_CAP_WRITE_MAP | BDI_CAP_EXEC_MAP)
@@ -304,6 +305,11 @@ static inline bool bdi_cap_swap_backed(s
 	return bdi->capabilities & BDI_CAP_SWAP_BACKED;
 }
 
+static inline bool bdi_cap_page_constant_write(struct backing_dev_info *bdi)
+{
+	return bdi->capabilities & BDI_CAP_PAGE_CONSTANT_WRITE;
+}
+
 static inline bool bdi_cap_flush_forker(struct backing_dev_info *bdi)
 {
 	return bdi == &default_backing_dev_info;
@@ -324,6 +330,10 @@ static inline bool mapping_cap_swap_back
 	return bdi_cap_swap_backed(mapping->backing_dev_info);
 }
 
+static inline bool mapping_cap_page_constant_write(struct address_space *mapping) {
+	return bdi_cap_page_constant_write(mapping->backing_dev_info);
+}
+
 static inline int bdi_sched_wait(void *word)
 {
 	schedule();
Index: linux-2.6.32-131.0.15.el6.x86_64/include/linux/page-flags.h
===================================================================
--- linux-2.6.32-131.0.15.el6.x86_64.orig/include/linux/page-flags.h	2011-05-10 21:37:57.000000000 +0300
+++ linux-2.6.32-131.0.15.el6.x86_64/include/linux/page-flags.h	2011-05-19 21:06:31.000000000 +0300
@@ -111,6 +111,7 @@ enum pageflags {
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 	PG_compound_lock,
 #endif
+	PG_constant,
 	__NR_PAGEFLAGS,
 
 	/* Filesystems */
@@ -214,6 +215,7 @@ PAGEFLAG(Pinned, pinned) TESTSCFLAG(Pinn
 PAGEFLAG(SavePinned, savepinned);			/* Xen */
 PAGEFLAG(Reserved, reserved) __CLEARPAGEFLAG(Reserved, reserved)
 PAGEFLAG(SwapBacked, swapbacked) __CLEARPAGEFLAG(SwapBacked, swapbacked)
+PAGEFLAG(Constant, constant)
 
 __PAGEFLAG(SlobFree, slob_free)
 
