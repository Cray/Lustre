diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c
index c0d4dae..b3dacc5 100644
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@ -223,10 +223,12 @@ static void __release_stripe(raid5_conf_t *conf, struct stripe_head *sh)
 			if (test_bit(STRIPE_DELAYED, &sh->state)) {
 				list_add_tail(&sh->lru, &conf->delayed_list);
 				blk_plug_device(conf->mddev->queue);
+				atomic_inc(&conf->delayed);
 			} else if (test_bit(STRIPE_BIT_DELAY, &sh->state) &&
 				   sh->bm_seq - conf->seq_write > 0) {
 				list_add_tail(&sh->lru, &conf->bitmap_list);
 				blk_plug_device(conf->mddev->queue);
+				atomic_inc(&conf->bit_delayed);
 			} else {
 				clear_bit(STRIPE_BIT_DELAY, &sh->state);
 				list_add_tail(&sh->lru, &conf->handle_list);
@@ -409,6 +411,7 @@ get_active_stripe(raid5_conf_t *conf, sector_t sector,
 			if (noblock && sh == NULL)
 				break;
 			if (!sh) {
+				atomic_inc(&conf->out_of_stripes);
 				conf->inactive_blocked = 1;
 				wait_event_lock_irq(conf->wait_for_stripe,
 						    !list_empty(&conf->inactive_list) &&
@@ -432,6 +435,10 @@ get_active_stripe(raid5_conf_t *conf, sector_t sector,
 				    !test_bit(STRIPE_EXPANDING, &sh->state))
 					BUG();
 				list_del_init(&sh->lru);
+				if (test_bit(STRIPE_DELAYED, &sh->state))
+					atomic_dec(&conf->delayed);
+				if (test_bit(STRIPE_BIT_DELAY, &sh->state))
+					atomic_dec(&conf->bit_delayed);
 			}
 		}
 	} while (sh == NULL);
@@ -469,10 +476,13 @@ static void ops_run_io(struct stripe_head *sh, struct stripe_head_state *s)
 		bi = &sh->dev[i].req;
 
 		bi->bi_rw = rw;
-		if (rw == WRITE)
+		if (rw == WRITE) {
+			atomic_inc(&conf->writes_out);
 			bi->bi_end_io = raid5_end_write_request;
-		else
+		} else {
+			atomic_inc(&conf->reads_out);
 			bi->bi_end_io = raid5_end_read_request;
+		}
 
 		rcu_read_lock();
 		rdev = rcu_dereference(conf->disks[i].rdev);
@@ -507,6 +517,7 @@ static void ops_run_io(struct stripe_head *sh, struct stripe_head_state *s)
 			    test_bit(R5_ReWrite, &sh->dev[i].flags))
 				atomic_add(STRIPE_SECTORS,
 					&rdev->corrected_errors);
+			atomic_inc(&conf->out_reqs_in_queue);
 			generic_make_request(bi);
 		} else {
 			if (rw == WRITE)
@@ -1553,6 +1566,8 @@ static void raid5_end_read_request(struct bio * bi, int error)
 	mdk_rdev_t *rdev;
 
 
+	atomic_dec(&conf->out_reqs_in_queue);
+
 	for (i=0 ; i<disks; i++)
 		if (bi == &sh->dev[i].req)
 			break;
@@ -1633,6 +1648,8 @@ static void raid5_end_write_request(struct bio *bi, int error)
 	int disks = sh->disks, i;
 	int uptodate = test_bit(BIO_UPTODATE, &bi->bi_flags);
 
+	atomic_dec(&conf->out_reqs_in_queue);
+
 	for (i=0 ; i<disks; i++)
 		if (bi == &sh->dev[i].req)
 			break;
@@ -2604,6 +2604,7 @@ static void handle_stripe_dirtying5(raid5_conf_t *conf,
 					set_bit(R5_LOCKED, &dev->flags);
 					set_bit(R5_Wantread, &dev->flags);
 					s->locked++;
+					atomic_inc(&conf->reads_for_rmw);
 				} else {
 					set_bit(STRIPE_DELAYED, &sh->state);
 					set_bit(STRIPE_HANDLE, &sh->state);
@@ -2627,6 +2628,7 @@ static void handle_stripe_dirtying5(raid5_conf_t *conf,
 					set_bit(R5_LOCKED, &dev->flags);
 					set_bit(R5_Wantread, &dev->flags);
 					s->locked++;
+					atomic_inc(&conf->reads_for_rcw);
 				} else {
 					set_bit(STRIPE_DELAYED, &sh->state);
 					set_bit(STRIPE_HANDLE, &sh->state);
@@ -2677,6 +2679,7 @@ static void handle_stripe_dirtying6(raid5_conf_t *conf,
 				set_bit(R5_LOCKED, &dev->flags);
 				set_bit(R5_Wantread, &dev->flags);
 				s->locked++;
+				atomic_inc(&conf->reads_for_rcw);
 			} else {
 				pr_debug("Request delayed stripe %llu "
 					"block %d for Reconstruct\n",
@@ -3027,6 +3044,8 @@ static void handle_stripe5(struct stripe_head *sh)
 	clear_bit(STRIPE_HANDLE, &sh->state);
 	clear_bit(STRIPE_DELAYED, &sh->state);
 
+	atomic_inc(&conf->handle_called);
+
 	s.syncing = test_bit(STRIPE_SYNCING, &sh->state);
 	s.expanding = test_bit(STRIPE_EXPAND_SOURCE, &sh->state);
 	s.expanded = test_bit(STRIPE_EXPAND_READY, &sh->state);
@@ -3331,6 +3334,8 @@ static void handle_stripe6(struct stripe_head *sh)
 	clear_bit(STRIPE_HANDLE, &sh->state);
 	clear_bit(STRIPE_DELAYED, &sh->state);
 
+	atomic_inc(&conf->handle_called);
+
 	s.syncing = test_bit(STRIPE_SYNCING, &sh->state);
 	s.expanding = test_bit(STRIPE_EXPAND_SOURCE, &sh->state);
 	s.expanded = test_bit(STRIPE_EXPAND_READY, &sh->state);
@@ -3602,6 +3621,7 @@ static void raid5_activate_delayed(raid5_conf_t *conf)
 			if (!test_and_set_bit(STRIPE_PREREAD_ACTIVE, &sh->state))
 				atomic_inc(&conf->preread_active_stripes);
 			list_add_tail(&sh->lru, &conf->hold_list);
+			atomic_dec(&conf->delayed);
 		}
 	} else
 		blk_plug_device(conf->mddev->queue);
@@ -3875,7 +3895,8 @@ static int chunk_aligned_read(mddev_t *mddev, struct bio * raid_bio)
 				    conf->device_lock, /* nothing */);
 		atomic_inc(&conf->active_aligned_reads);
 		spin_unlock_irq(&conf->device_lock);
-
+		atomic_inc(&conf->out_reqs_in_queue);
+		atomic_inc(&conf->reads_out);
 		generic_make_request(align_bi);
 		return 1;
 	} else {
@@ -3948,6 +3968,8 @@ static int make_request(mddev_t *mddev, struct bio * bi)
 	const int rw = bio_data_dir(bi);
 	int remaining;
 
+	atomic_inc(&conf->in_reqs_in_queue);
+
 	if (unlikely(bio_rw_flagged(bi, BIO_RW_BARRIER))) {
 		/* Drain all pending writes.  We only really need
 		 * to ensure they have been submitted, but this is
@@ -3889,6 +3985,11 @@ static int make_request(mddev_t *mddev, struct bio * bi)
 
 	md_write_start(mddev, bi);
 
+	if (rw == WRITE)
+		atomic_inc(&conf->writes_in);
+	else
+		atomic_inc(&conf->reads_in);
+
 	if (rw == READ &&
 		mddev->reshape_position == MaxSector &&
 		chunk_aligned_read(mddev,bi))
@@ -4092,7 +4119,7 @@ static int make_request(mddev_t *mddev, struct bio * bi)
 
 		if ( rw == WRITE )
 			md_write_end(mddev);
-
+		atomic_dec(&conf->in_reqs_in_queue);
 		bio_endio(bi, 0);
 	}
 
@@ -4532,6 +4559,7 @@ static void raid5d(mddev_t *mddev)
 		spin_unlock_irq(&conf->device_lock);
 		
 		handled++;
+		atomic_inc(&conf->handled_in_raid5d);
 		handle_stripe(sh);
 		release_stripe(sh);
 		cond_resched();
@@ -5256,6 +5284,22 @@ static void status(struct seq_file *seq, mddev_t *mddev)
 			       conf->disks[i].rdev &&
 			       test_bit(In_sync, &conf->disks[i].rdev->flags) ? "U" : "_");
 	seq_printf (seq, "]");
+	seq_printf (seq, "\n\t\tin: %u reads, %u writes; out: %u reads, %u writes, %u zwrites",
+			atomic_read(&conf->reads_in), atomic_read(&conf->writes_in),
+			atomic_read(&conf->reads_out), atomic_read(&conf->writes_out),
+			atomic_read(&conf->writes_zcopy));
+	seq_printf (seq, "\n\t\t%u in raid5d, %u out of stripes, %u handle called",
+			atomic_read(&conf->handled_in_raid5d),
+			atomic_read(&conf->out_of_stripes),
+			atomic_read(&conf->handle_called));
+	seq_printf (seq, "\n\t\treads: %u for rmw, %u for rcw",
+			atomic_read(&conf->reads_for_rmw),
+			atomic_read(&conf->reads_for_rcw));
+	seq_printf (seq, "\n\t\t%u delayed, %u bit delayed, %u active, queues: %u in, %u out\n",
+			atomic_read(&conf->delayed), atomic_read(&conf->bit_delayed),
+			atomic_read(&conf->active_stripes),
+			atomic_read(&conf->in_reqs_in_queue),
+			atomic_read(&conf->out_reqs_in_queue));
 #ifdef DEBUG
 	seq_printf (seq, "\n");
 	printall(seq, conf);
diff --git a/drivers/md/raid5.h b/drivers/md/raid5.h
index 972ac47..30d1492 100644
--- a/drivers/md/raid5.h
+++ b/drivers/md/raid5.h
@@ -434,6 +434,25 @@ struct raid5_private_data {
 	 * the new thread here until we fully activate the array.
 	 */
 	struct mdk_thread_s	*thread;
+
+	/*
+	 * Stats
+	 */
+	atomic_t		reads_in;
+	atomic_t		writes_in;
+	atomic_t		reads_out;
+	atomic_t		writes_out;
+	atomic_t		handled_in_raid5d;
+	atomic_t		out_of_stripes;
+	atomic_t		reads_for_rmw;
+	atomic_t		reads_for_rcw;
+	atomic_t		writes_zcopy;
+	atomic_t		writes_copied;
+	atomic_t		handle_called;
+	atomic_t		delayed;
+	atomic_t		bit_delayed;
+	atomic_t		in_reqs_in_queue;
+	atomic_t		out_reqs_in_queue;
 };
 
 typedef struct raid5_private_data raid5_conf_t;
